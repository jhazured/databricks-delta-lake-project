name: Databricks Delta Lake CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run security checks daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - prod
        - trial

env:
  PYTHON_VERSION: '3.11'
  JAVA_VERSION: '11'

jobs:
  # Code Quality and Linting
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/pyproject.toml') }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Lint with flake8
      run: |
        flake8 utils/ scripts/ api/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 utils/ scripts/ api/ --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
    
    - name: Check code formatting with black
      run: |
        black --check utils/ scripts/ api/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only utils/ scripts/ api/
    
    - name: Type checking with mypy
      run: |
        mypy utils/ scripts/ api/ --ignore-missing-imports

  # Matrix testing across Python versions
  test:
    runs-on: ubuntu-latest
    needs: [code-quality]
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
        java-version: ['11', '17']
        exclude:
          # Only test Java 17 with Python 3.11
          - python-version: '3.9'
            java-version: '17'
          - python-version: '3.10'
            java-version: '17'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Set up Java ${{ matrix.java-version }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ matrix.java-version }}
        distribution: 'temurin'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Lint with flake8
      run: |
        flake8 scripts/ utils/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 scripts/ utils/ --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
    
    - name: Check code formatting with black
      run: |
        black --check scripts/ utils/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only scripts/ utils/
    
    - name: Type checking with mypy
      run: |
        mypy scripts/ utils/ --ignore-missing-imports
    
    - name: Run unit tests
      run: |
        pytest testing/unit/ -v --cov=scripts --cov=utils --cov-report=xml --cov-report=term-missing
    
    - name: Run integration tests
      if: matrix.python-version == '3.11' && matrix.java-version == '11'
      run: |
        pytest testing/integration/ -v -m "not slow"
      env:
        # Add test environment variables here
        TEST_MODE: "ci"
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11' && matrix.java-version == '11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Security scanning
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit semgrep
    
    - name: Run safety check
      run: |
        safety check --json --output safety-report.json || true
    
    - name: Run bandit security linter
      run: |
        bandit -r scripts/ utils/ api/ -f json -o bandit-report.json || true
    
    - name: Run Semgrep security scan
      run: |
        semgrep --config=auto --json --output=semgrep-report.json utils/ scripts/ api/ || true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json
          semgrep-report.json

  # Docker Build and Test
  docker-tests:
    runs-on: ubuntu-latest
    needs: [code-quality]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build development image
      run: |
        docker build --target development -t delta-lake-dev:latest .
    
    - name: Build production image
      run: |
        docker build --target production -t delta-lake-prod:latest .
    
    - name: Build API image
      run: |
        docker build --target api -t delta-lake-api:latest .
    
    - name: Build data processing image
      run: |
        docker build --target data-processing -t delta-lake-processor:latest .
    
    - name: Test development image
      run: |
        docker run --rm delta-lake-dev:latest python -c "import utils.common; print('Import successful')"
    
    - name: Test production image
      run: |
        docker run --rm delta-lake-prod:latest python -c "import utils.common; print('Import successful')"

  # Kubernetes Manifest Validation
  kubernetes-validation:
    runs-on: ubuntu-latest
    needs: [docker-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'
    
    - name: Validate Kubernetes manifests
      run: |
        # Validate YAML syntax
        for file in infrastructure/kubernetes/*.yaml; do
          echo "Validating $file"
          kubectl --dry-run=client apply -f "$file"
        done
    
    - name: Check Kubernetes best practices
      run: |
        # Check for common issues
        echo "Checking for hardcoded secrets..."
        grep -r "password\|secret\|token" infrastructure/kubernetes/ || echo "No hardcoded secrets found"
        
        echo "Checking for resource limits..."
        grep -r "resources:" infrastructure/kubernetes/ || echo "No resource limits found"

  # Terraform Validation
  terraform-validation:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: '1.5.0'
    
    # Check Terraform code formatting
    - name: Terraform Format Check
      run: |
        cd infrastructure/terraform
        terraform fmt -check -recursive
    
    # Initialize Terraform without backend to avoid S3 state requirements
    # This allows validation without needing actual AWS credentials or S3 bucket
    - name: Terraform Init (No Backend)
      run: |
        cd infrastructure/terraform
        terraform init -backend=false
    
    # Validate Terraform configuration syntax and structure
    # This works after init -backend=false since no backend state is required
    - name: Terraform Validate
      run: |
        cd infrastructure/terraform
        terraform validate
    
    # Note: We skip terraform plan in CI/CD since it requires real provider credentials
    # The terraform validate step above is sufficient to check configuration syntax
    # For actual deployment, terraform plan would be run with proper credentials

  # Performance testing
  performance:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Set up Java
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Run performance tests
      run: |
        pytest testing/performance/ -v --benchmark-only --benchmark-save=performance-baseline
      env:
        TEST_MODE: "performance"

  # Build and package
  build:
    runs-on: ubuntu-latest
    needs: [test, security, docker-tests, kubernetes-validation, terraform-validation]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Build package
      run: |
        python -m build
    
    - name: Check package
      run: |
        twine check dist/*
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: python-package-distributions
        path: dist/

  # Deploy to Databricks (conditional based on trigger)
  deploy:
    runs-on: ubuntu-latest
    needs: [build, performance]
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'workflow_dispatch')
    environment: ${{ github.event.inputs.environment || 'production' }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: python-package-distributions
        path: dist/
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Databricks CLI
      run: |
        pip install databricks-cli
    
    - name: Configure Databricks CLI
      run: |
        echo "${{ secrets.DATABRICKS_HOST }}" | databricks configure --token
      env:
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
    
    - name: Deploy to Databricks
      run: |
        # Upload wheel to Databricks workspace
        databricks fs cp dist/*.whl dbfs:/FileStore/jars/
        
        # Install package in workspace
        databricks libraries install --cluster-id ${{ secrets.DATABRICKS_CLUSTER_ID }} --whl dbfs:/FileStore/jars/databricks-delta-lake-project-*.whl
        
        # Run deployment scripts
        python scripts/deployment/deploy.py --environment production
      env:
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}

  # Test Results Summary
  test-summary:
    runs-on: ubuntu-latest
    needs: [code-quality, test, security, docker-tests, kubernetes-validation, terraform-validation, build]
    if: always()
    
    steps:
    - name: Test Results Summary
      run: |
        echo "## ðŸ§ª Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "### âœ… Passed Jobs:" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.code-quality.result }}" == "success" ]; then
          echo "- âœ… Code Quality" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.test.result }}" == "success" ]; then
          echo "- âœ… Unit Tests (Matrix)" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.security.result }}" == "success" ]; then
          echo "- âœ… Security Scan" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.docker-tests.result }}" == "success" ]; then
          echo "- âœ… Docker Tests" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.kubernetes-validation.result }}" == "success" ]; then
          echo "- âœ… Kubernetes Validation" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.terraform-validation.result }}" == "success" ]; then
          echo "- âœ… Terraform Validation" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.build.result }}" == "success" ]; then
          echo "- âœ… Build Package" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### âŒ Failed Jobs:" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.code-quality.result }}" == "failure" ]; then
          echo "- âŒ Code Quality" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.test.result }}" == "failure" ]; then
          echo "- âŒ Unit Tests (Matrix)" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.security.result }}" == "failure" ]; then
          echo "- âŒ Security Scan" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.docker-tests.result }}" == "failure" ]; then
          echo "- âŒ Docker Tests" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.kubernetes-validation.result }}" == "failure" ]; then
          echo "- âŒ Kubernetes Validation" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.terraform-validation.result }}" == "failure" ]; then
          echo "- âŒ Terraform Validation" >> $GITHUB_STEP_SUMMARY
        fi
        if [ "${{ needs.build.result }}" == "failure" ]; then
          echo "- âŒ Build Package" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Overall Status:" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.build.result }}" == "success" ]; then
          echo "ðŸŽ‰ **All tests passed!** Ready for deployment." >> $GITHUB_STEP_SUMMARY
        else
          echo "âš ï¸ **Some tests failed.** Please review the logs above." >> $GITHUB_STEP_SUMMARY
        fi